---
title: resume
theme: ./theme/basic
layout: cover
---

# 个人经历和成果展示

@yxonic

---

# 简介

- 中科大陈恩红老师博士生
- 在实验室担任智慧教育方向研究组的组长
- 研究兴趣和方向主要包括：教育数据挖掘，自然语言处理，多模态表征，强化学习等
- 自我评价，两个突出亮点：
  - 致力于做有影响力的研究
    - Google Scholar 总引用量 808, h-index 11
  - 有着较强的 0-1 实现能力
    - 代码能力：多年编程经历，熟悉多种编程语言，NOI 国家奖牌，并行优化、RDMA 编程比赛第一
    - 工程能力：丰富的开源项目，开发实验室 CODIA 和 LUNA 平台
    - 学习能力：涉猎广泛，喜欢跟踪最前沿的研究和技术，快速学习和上手能力

---

# 个人经历：教育组

- 在刘淇老师、黄振亚老师指导下成立教育组，作为组长领导组员探索教育数据挖掘相关领域，如问题理解、学生建模、自适应学习和推荐等，指导小组成员发表 20 余篇学术论文。
- 定期组织小组讨论和技术报告，增强组内及组间的沟通和协作。
- 搭建教育组网站分享小组研究进展和开放资源，促进开放研究。
- 带领小组在 GitHub 上开源教育相关的数据、模型和工具等相关资源。

<div class="mt-6 grid place-items-center grid-cols-2">
  <img
    src="/imgs/resume/base_group.png"
    alt="BASE Group"
    class="h-48 outline outline-gray-300"
  />
  <img
    src="/imgs/resume/bdaa_github.png"
    alt="BDAA GitHub"
    class="h-48 outline outline-gray-300"
  />
</div>

---

# 个人经历：CODIA

- 从零开始搭建智能在线编程平台 CODIA，使用 Vue + Node.js 设计并实现了初始网站架构和基于 GraphQL 的业务 API，并基于 gRPC 和 Kafka 实现可扩展的微服务架构。
- 将教育组的用户建模和自适应学习等相关研究应用到平台上，指导团队成员将知识追踪和试题推荐模型封装为 gRPC 服务，为用户提供智能诊断和推荐。
- 搭建基于 GitLab 和 Kubernetes 的 DevOps+MLOps 平台，用于 CODIA 的持续部署，提高团队工作效率、降低协作成本。
- 已多次作为中科大多门编程和算法课程的教学平台，为计算机专业学生提供更好的学习体验。

<div class="mt-4 grid place-items-center grid-cols-2">
  <img
    src="/imgs/resume/codia_home.png"
    alt="CODIA home"
    class="h-40 outline outline-gray-300"
  />
  <img
    src="/imgs/resume/codia_dev.png"
    alt="CODIA dev"
    class="h-40 outline outline-gray-300"
  />
</div>

---

# 个人经历：教育部考试中心

- 面向考试中心海量题库，训练基于大规模语义预训练的试题表征模型，提升试题属性自动标注效果。
- 基于考试中心真实场景探索新的研究课题，例如试卷分割、试题查重、相似题推荐和替换等，相关成果用于开发考试中心内部工具，以及实验室智慧教育知识图谱平台 LUNA。
- 就如何将深度学习应用于传统教育技术中，在考试中心内部开展报告和讲座。

<div class="mt-6 grid place-items-center grid-cols-2">
  <img
    src="/imgs/resume/luna_home.png"
    alt="LUNA home"
    class="h-48 outline outline-gray-300"
  />
  <img
    src="/imgs/resume/luna_demo.png"
    alt="LUNA demo"
    class="h-48 outline outline-gray-300"
  />
</div>

---

# 个人经历：科大讯飞

- 基于基础 NLP 技术开展题库建设、公式提取和相似题推荐等任务，并参与重构讯飞内部海量试题库以及相似题检索系统。
- 使用深度学习方法进行试题理解和难度估计等任务，参与开发和优化相关模型，在高考试题难度预测准确性和稳定性指标上超过领域专家。
- 在知识追踪任务中引入试题题面文本信息，实现了了一种试题增强的知识追踪方法，大幅提升学生得分预测的效果。

<div class="mt-2 grid place-items-center grid-cols-1">
  <img
    src="/imgs/resume/eernn.png"
    alt="EERNN model"
    class="h-48 outline outline-gray-300"
  />
</div>

---

# 研究成果：Spotlight

- 任务：结构化图像转写（典型例子：公式识别为 LaTeX）
- 挑战：attention 更注重内容相关，忽略图像内在结构
- Spotlight 贡献：
  - spotlight 每个时刻关注一个点，以围绕中心点的高斯分布作为权重聚合
  - 设计了两种策略控制聚焦中心的移动
  - 引入强化学习，帮助模型学习更加合理的阅读路径
- 以现在的研究观点来看，spotlight 可以和 multi-head attention 优势互补，可以从下面几个方向改进：
  - 实现 multi-head spotlight（近期工作）
  - 使用 PPO 算法优化 spotlight actor（近期工作）
  - 和 Transformer 架构适配，去掉序列依赖，从而能够和 multi-head attention 配合使用
  - 利用局部性特征，通过定义底层计算忽略低权重位置，从而降低复杂度、提高效率

---

# Spotlight 模型

<div class="mt-8 grid place-items-center grid-cols-1">
  <img
    src="/imgs/resume/spotlight.png"
    alt="Spotlight model"
    class="h-72 outline outline-gray-300"
  />
</div>

---

# 研究成果：QuesNet

- 任务：无监督预训练试题表征
- 挑战：domain-specific，多模态
- QuesNet 贡献：
  - 多模态输入表示
  - 通过双向 LSTM 和 self attention，分别得到 token 层和问题层表征
  - 设计了双向 LSTM 上的类 BERT 预训练任务
  - 引入 domain-specific task 多任务学习
- 以现在的研究观点来看，QuesNet 可以从以下角度进一步改进：
  - 通用大模型 $\to$ in-domain 大模型 $\to$ domain-specific 任务微调
  - 架构上更好地适配教育 domain 的多模态输入，特别是数学公式、几何图形等

---

<div class="mt-4 grid place-items-center grid-cols-1 gap-8">
  <img
    src="/imgs/resume/quesnet_arch.png"
    alt="QuesNet model"
    class="w-screen-sm outline outline-gray-300"
  />
  <img
    src="/imgs/resume/quesnet_train.png"
    alt="QuesNet training"
    class="w-screen-sm outline outline-gray-300"
  />
</div>

---

# 研究成果：EKT 和 DTransformer

- 任务：知识追踪
- 目标：根据学生做题记录估计学生在每个时刻的知识掌握状态
- EKT 贡献：
  - **第一个**在 KT 中引入试题文本的工作（之前的工作均基于知识点 embedding）
  - 通过对文本 attention 聚合最相关的历史记录
  - 通过对知识矩阵 attention 形成每个知识点上的追踪
- DTransformer 贡献：
  - **第一个**使用 Transformer 诊断知识状态的工作（之前的工作只能做成绩预测）
  - 设计 DTransformer 架构，实现从问题层面到知识层面的能力诊断
  - 设计对比学习损失提升知识状态的稳定性

---

# EKT 模型

<div class="mt-8 grid place-items-center grid-cols-1">
  <img
    src="/imgs/resume/ekt.png"
    alt="EKT model"
    class="h-72 outline outline-gray-300"
  />
</div>

---

# DTransformer 模型

<div class="mt-8 grid place-items-center grid-cols-1">
  <img
    src="/imgs/resume/dtransformer.png"
    alt="DTransformer model"
    class="h-72 outline outline-gray-300"
  />
</div>

---

# Recent Interests: LLM

- 跟进 LLM 最新进展
- 从开源 LLM 源码学习（LLaMA, Alpaca, ColossalChat）
  - HuggingFace: tokenizers, transformers (model, trainer, etc.)
  - PyTorch 分布式训练
  - 指令微调
  - RLHF: reward model, PPO 算法
- 兴趣方向：
  - LLM 增强（外部知识，插件，专用模型等）
  - LLM 应用（new Bing, GitHub, Office）
  - 低成本微调和预测

---

<div class="mt-16 grid place-items-center grid-cols-1">
  <img
    src="/imgs/resume/rlhf_colossal.jpeg"
    alt="ColossalChat RLHF"
    class="h-72 outline outline-gray-300"
  />
</div>

---

# Recent Interests: vslides

- 这张幻灯片是用 vslides 做的
- 目标：
  - 喜欢技术分享，需要一个更方便创作的工具
  - 基于 Web 技术来做内容呈现，既方便排版设计，又方便在网上分享
- 技术栈：
  - remark：支持用 Markdown 编写内容
  - vue：用于幻灯片组件开发
  - vite：用于快速预览结果，以及生成静态网站
- 整体功能分四个组件实现：
  - core：基础功能组件，包括幻灯片展示，翻页功能，主题机制等
  - parser：负责将原始 Markdown 内容解析为幻灯片页面及配置
  - vite-plugin：vite 插件，负责实现幻灯片热重载、静态网站生成等
  - CLI：组合以上组件，形成用于命令行开启幻灯片的 CLI 工具

---

# Q&A

<!--

# Reference

- [Preparation cheet sheet](https://sites.google.com/view/datascience-cheat-sheets)
- [ML interview](https://towardsdatascience.com/types-of-machine-learning-interviews-and-how-to-ace-them-51587a95f847)
- [Soft skill interview](https://towardsdatascience.com/how-to-prepare-for-a-behavioral-soft-skills-interview-cheat-sheet-9347aaeaef82)
- [ML system interview](https://towardsdatascience.com/what-is-machine-learning-system-design-interview-and-how-to-prepare-for-it-537d1271d754)
- [Resume](https://aqeel-anwar.medium.com/machine-learning-resume-that-got-me-shortlisted-for-meta-microsoft-nvidia-uber-samsung-intel-220761c1a850)
- [Resume dos and don'ts](https://aqeel-anwar.medium.com/the-dos-and-donts-of-a-software-engineer-resume-to-get-you-shortlisted-for-interviews-more-7d6a926156c0)
- [deep learning interviews](https://arxiv.org/abs/2201.00650) -->
